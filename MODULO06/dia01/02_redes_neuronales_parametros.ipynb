{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"vGO_8vwX16CQ","executionInfo":{"status":"ok","timestamp":1747608242347,"user_tz":300,"elapsed":22605,"user":{"displayName":"Rosa Torres","userId":"06889151810241872089"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from keras.datasets import mnist\n","from keras import layers,models\n","from keras.utils import to_categorical"]},{"cell_type":"code","source":["(train_data,train_labels),(test_data,test_labels) = mnist.load_data()\n","x_train = train_data.reshape((60000,28*28))\n","x_train = x_train.astype('float32')/255\n","x_test = test_data.reshape((10000,28*28))\n","x_test = x_test.astype('float32')/255\n","y_train = to_categorical(train_labels)\n","y_test = to_categorical(test_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FAbnGFXJ2FzJ","outputId":"aae0e898-d929-492d-f759-0aca9dd612ff","executionInfo":{"status":"ok","timestamp":1747608296720,"user_tz":300,"elapsed":627,"user":{"displayName":"Rosa Torres","userId":"06889151810241872089"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]}]},{"cell_type":"markdown","source":["# Clase models.Sequential"],"metadata":{"id":"TAZb4dwl2ZMM"}},{"cell_type":"markdown","source":["representa un modelo secuencial, el cual se compone de una pila lineal de capas. Se usa cuando las capas se organizan de manera secuencial, es decir, una después de otra, sin conexiones más complejas como en modelos con múltiples entradas o salidas."],"metadata":{"id":"rQ0GSoe12qv9"}},{"cell_type":"code","source":["model = models.Sequential()\n"],"metadata":{"id":"GIgvLaDg2wx8","executionInfo":{"status":"ok","timestamp":1747608326107,"user_tz":300,"elapsed":43,"user":{"displayName":"Rosa Torres","userId":"06889151810241872089"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# 📌 Dense(units, activation, input_shape)\n","\n","La capa `Dense` es una capa completamente conectada (*fully connected*), donde cada neurona de la capa está conectada con todas las neuronas de la capa anterior."],"metadata":{"id":"6EedHEEg2ebb"}},{"cell_type":"markdown","source":["## PARAMETROS DE DENSE"],"metadata":{"id":"FpMbdRAu3EOL"}},{"cell_type":"markdown","source":["## 1️⃣ `units` → Número de neuronas  \n","\n","### 📌 Descripción  \n","Este parámetro define cuántas neuronas tendrá la capa. Más neuronas pueden capturar patrones más complejos, pero también pueden hacer que el modelo sea más costoso computacionalmente y propenso al sobreajuste."],"metadata":{"id":"No0ZBywL3Fxs"}},{"cell_type":"markdown","source":["## 🔥 `activation` → Función de activación  \n","\n","### 📌 Descripción  \n","Determina cómo se procesará la salida de cada neurona. Las activaciones añaden no linealidad para que la red aprenda relaciones complejas.\n","\n","### 📌 Ejemplo  \n","```python\n","Dense(64, activation=\"relu\")```"],"metadata":{"id":"nZO6rpW03TU7"}},{"cell_type":"markdown","source":["### 📌 Funciones de activación más usadas  \n","\n","| **Activación** | **Descripción** | **Uso común** |\n","|--------------|---------------|-------------|\n","| `relu`      | `max(0, x)`, elimina valores negativos | Capas ocultas en redes profundas |\n","| `sigmoid`   | Convierte valores en rango (0,1) | Clasificación binaria |\n","| `softmax`   | Convierte valores en probabilidades sumando 1 | Clasificación multiclase |\n","| `tanh`      | Rango (-1,1), más centrado que `sigmoid` | Modelos recurrentes (RNN, LSTM) |"],"metadata":{"id":"PU5d9XqI3dm1"}},{"cell_type":"markdown","source":["## 🏗️ `input_shape` → Forma de la entrada  \n","\n","### 📌 Descripción  \n","Este parámetro solo se usa en la primera capa para definir el tamaño de los datos de entrada.\n","\n","### 📌 Ejemplo  \n","Si tenemos 10 características en nuestros datos:\n"],"metadata":{"id":"YdM-Ilul3v9d"}},{"cell_type":"code","source":["model = models.Sequential()\n","model.add(layers.Dense(512,activation='relu',input_shape=(28*28,)))\n","model.add(layers.Dense(10,activation='softmax'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EDO5zOxR25QH","outputId":"c7eff98f-337a-4326-c34b-fc7b034e6c16"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]}]},{"cell_type":"markdown","source":["## ⚙️ `model.compile()` → Configuración del modelo  \n","\n","La función `model.compile()` se usa para configurar el modelo antes del entrenamiento, definiendo el optimizador, la función de pérdida y las métricas de evaluación.\n","\n","### 📌 Parámetros  \n","\n","- **`optimizer=\"adam\"`** → Algoritmo de optimización que ajusta los pesos del modelo para minimizar el error.  \n","  - `adam` (*Adaptive Moment Estimation*) es uno de los optimizadores más utilizados porque combina las ventajas de `SGD` con momentums y adaptabilidad en la tasa de aprendizaje.\n","\n","- **`loss=\"mse\"`** → Función de pérdida que mide el error del modelo durante el entrenamiento.  \n","  - `mse` (*Mean Squared Error*) es comúnmente usada en problemas de regresión, calculando la media de los errores al cuadrado entre predicciones y valores reales.\n","\n","- **`metrics=[\"mae\"]`** → Lista de métricas para evaluar el rendimiento del modelo.  \n","  - `mae` (*Mean Absolute Error*) mide el error absoluto promedio entre predicciones y valores reales, útil en problemas de regresión.\n","\n","### 📌 Ejemplo de uso  \n"],"metadata":{"id":"BlSjYFA54NA0"}},{"cell_type":"code","source":["model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"],"metadata":{"id":"QX7Jux1A4mS8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 🚀 Optimizadores en Deep Learning  \n","\n","Los optimizadores ajustan los pesos del modelo para minimizar la función de pérdida y mejorar el rendimiento. A continuación, se presentan algunos de los más utilizados:\n","\n","## 📌 Optimizadores más usados  \n","\n","## 📌 Comparación de Optimizadores\n","\n","| Optimizador | Ventajas | Desventajas | Uso común |\n","|------------|----------|------------|-----------|\n","| **SGD** | Simple y eficiente | Puede quedar atrapado en mínimos locales | Modelos pequeños |\n","| **Adam** | Convergencia rápida | Puede ser inestable | Generalmente recomendado |\n","| **RMSprop** | Buen manejo de gradientes | No siempre converge | Series temporales, RNNs |\n","| **Adagrad** | Aprende bien en datos dispersos | Tasa de aprendizaje decrece mucho | NLP, datos escasos |\n","| **Adadelta** | No requiere tasa de aprendizaje inicial | Costoso computacionalmente | Datos ruidosos |\n","| **Adamax** | Funciona con grandes datasets | Menos usado que Adam | Redes profundas con ruido |\n","| **Nadam** | Convergencia rápida | Más costoso computacionalmente | Visión por computadora, NLP |"],"metadata":{"id":"z1lxx1x84wmM"}},{"cell_type":"markdown","source":["## 📌 Funciones de Pérdida y Métricas en Optimizadores\n","\n","## 🔹 Otras opciones para `loss`\n","| Función de Pérdida | Descripción | Uso común |\n","|--------------------|------------|-----------|\n","| **MSE** (Mean Squared Error) | Promedio de errores al cuadrado | Regresión |\n","| **MAE** (Mean Absolute Error) | Promedio de errores absolutos | Regresión |\n","| **Huber** | Similar a `mse`, pero menos sensible a outliers | Regresión robusta |\n","| **Binary Crossentropy** | Evalúa la diferencia entre probabilidades binarias | Clasificación binaria |\n","| **Categorical Crossentropy** | Para clases exclusivas (one-hot encoding) | Clasificación multiclase |\n","| **Sparse Categorical Crossentropy** | Para etiquetas enteras en vez de one-hot | Clasificación multiclase |\n","\n","---\n","\n","## 🔹 Otras opciones para `metrics`\n","| Métrica | Descripción | Uso común |\n","|---------|------------|-----------|\n","| **MAE** | Error absoluto medio | Regresión |\n","| **MSE** | Error cuadrático medio | Regresión |\n","| **MSLE** (Mean Squared Logarithmic Error) | Similar a `mse`, pero con valores logarítmicos | Regresión con valores grandes |\n","| **AUC** (Área bajo la curva ROC) | Evalúa la capacidad de clasificación | Clasificación binaria |\n","| **Accuracy** | Precisión de clasificación | Clasificación binaria o multiclase |\n"],"metadata":{"id":"2RQCJvo24tDt"}},{"cell_type":"markdown","source":["# ENTRENAMIENTO DEL MODELO"],"metadata":{"id":"shjuZKfq5Qv8"}},{"cell_type":"code","source":["model.fit(x_train,y_train,epochs=5,batch_size=128)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5FaewiZF5S2t","outputId":"705de0e2-6f57-4697-bf36-fac8428033de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8717 - loss: 0.4473\n","Epoch 2/5\n","\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9670 - loss: 0.1124\n","Epoch 3/5\n","\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9808 - loss: 0.0696\n","Epoch 4/5\n","\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0512\n","Epoch 5/5\n","\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9891 - loss: 0.0380\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7a82c6af5350>"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["* epochs=5 → El modelo entrenará sobre los mismos datos 5 veces.\n","* batch_size=128 → Cada actualización de pesos se hará después de procesar 128 muestras."],"metadata":{"id":"BksYyfVv5f8M"}}]}